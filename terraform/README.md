## [... existing code ...]


## terraform/README.md
# ğŸŒ Carolina Bandwidth Cloud Deployment

This guide helps you deploy **Carolina Bandwidth** to a live AWS EC2 instance using **Terraform + Docker**.

---

## âœ… Prerequisites

1. âœ… **AWS Account**
2. âœ… **Access Key & Secret Key** via IAM User
3. âœ… **Terraform Installed** â€“ https://www.terraform.io/downloads.html
4. âœ… **Docker Installed** â€“ https://docs.docker.com/get-docker/
5. âœ… **SSH Key Pair** created in AWS EC2 Console (for SSH access)

---

## ğŸ“¦ Setup Instructions

### Step 1: Set AWS Credentials

Either set environment variables:
```bash
export AWS_ACCESS_KEY_ID=your-access-key-id
export AWS_SECRET_ACCESS_KEY=your-secret-access-key
```

Or use a config file at `~/.aws/credentials`:
```ini
[default]
aws_access_key_id=your-access-key-id
aws_secret_access_key=your-secret-access-key
```

---

### Step 2: Configure Terraform Variables

In `terraform/variables.tf`:
```hcl
variable "aws_region"     { default = "us-east-1" }
variable "ami_id"         { default = "ami-0c55b159cbfafe1f0" } # Ubuntu 22.04 LTS
variable "instance_type" { default = "t3.medium" }
variable "key_name"      { default = "your-keypair-name" } # Set this to match your EC2 Key Pair
```

---

### Step 3: Deploy with Terraform

```bash
cd terraform
terraform init
terraform plan
terraform apply
```

Respond `yes` to confirm deployment.

---

### Step 4: Access Your App

Terraform will output a `public_ip` like:
```
Outputs:
public_ip = "3.123.456.78"
```

Then open:
```
http://3.123.456.78:8000/
```

You should see:
```json
{ "message": "Carolina Bandwidth is live" }
```

---

## ğŸ§  What Terraform Does

- Creates a security group that allows HTTP and SSH
- Deploys an EC2 instance
- Installs Docker and Git
- Clones the Carolina Bandwidth repo
- Launches it with Docker Compose

---

## ğŸ”’ SSH Access
Use your `.pem` file to SSH into the instance:
```bash
ssh -i path/to/your-key.pem ubuntu@3.123.456.78
```

---

## ğŸ§© Optional Extensions

- Use a **GPU instance** (e.g., `g4dn.xlarge`) for inference
- Add EBS volumes for persistent storage
- Setup HTTPS + Nginx
- Add custom domain via Route 53

---

## â“ Troubleshooting

- Terraform errors? Run `terraform destroy` and retry.
- Docker not running? SSH in and check `docker ps`.
- No access? Check your AWS security group ports (22 & 8000).

---

For help, DM @ChandieFae or consult the Genius âœ¨  
**Signature: CBNet â€“ Carolina Bandwidth Network (also: Chandra Brown & the Genius)**

---

## ğŸš€ CBNet Protocol Vision â€“ Scaling With the Universe

> "No AI left behind. No data lost. No bandwidth too small."

CBNet will evolve into a distributed AI transport system for edge-to-cloud intelligence. 

### ğŸ’¡ Whatâ€™s Coming:

- ğŸ›°ï¸ **CBNet Agents** â€“ Lightweight AI runners for edge devices, drones, remote sensors
- ğŸ§  **Adaptive Inference** â€“ Bandwidth-aware job switching (offline/online/cloud)
- ğŸ” **Queued Sync Layer** â€“ Offline-first storage that syncs when bandwidth returns
- âš¡ **Multi-node Federation** â€“ Models that collaborate across regions
- ğŸ” **CBNet Protocol Spec** â€“ Open AI infrastructure standard (coming soon)

**CBNet: A name. A mission. A movement. Scaling with the stars.**


## docs/CBNet_Protocol_Spec.md
# ğŸ“¡ CBNet Protocol Specification

The **CBNet Protocol** defines a modular, bandwidth-aware framework for distributed AI workloads. It supports scalable execution across devices, edge agents, cloud infrastructure, and offline/low-bandwidth scenarios.

---

## ğŸ¯ Purpose

To provide an open, fault-tolerant protocol for connecting AI models, data pipelines, and compute nodes with variable network constraints.

---

## ğŸ§± Architecture Overview

**Nodes:**
- **Edge Agent**: Local device running a lightweight AI job engine
- **Core Hub**: Central API or orchestrator (e.g. FastAPI server)
- **Cloud Worker**: Remote server or GPU instance

**Message Types:**
- Job Request (JSON)
- Job Result
- Sync Queue Entry
- Telemetry / Heartbeat

---

## ğŸ”„ Core Modules

| Module | Role |
|--------|------|
| `CBAgent` | Edge job executor and queue manager |
| `CBQueue` | Local-first buffer for delayed sync |
| `CBRouter` | Directs jobs to local/cloud based on availability |
| `CBTransport` | API + serialization for job/result handling |
| `CBMonitor` | Tracks performance and connectivity |

---

## ğŸ“¦ Job Lifecycle

1. **Create** â†’ Data/job appears on an edge node
2. **Queue** â†’ Added to CBQueue if offline
3. **Process** â†’ Run locally if model available
4. **Sync** â†’ If online, send result to Core Hub

---

## ğŸ“¡ Transport Layer

- All messages use signed JSON over HTTPS
- Async fallback supported via job receipts and polling
- Optional gRPC for high-throughput clusters

---

## ğŸ” Security

- Token-authenticated requests
- Data-at-rest encryption for queues
- TLS for all endpoints

---

## ğŸ§© Extensibility

- Add support for video, vision, embeddings
- Pluggable job types (e.g., transcription, summarization)
- Queue persistence (SQLite, Redis, S3)

---

## ğŸ› ï¸ Next Steps

- Define schema for CBJob and CBResult
- Implement base agent + queue modules
- Write reference orchestrator in FastAPI
- Launch open repo: `cbnet-protocol`

---

_ Carolina Bandwidth Last updated by CBNet Engineering â€” v0.1-alpha_


**Signature: CB â€“ Chandra Brown 
